<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Akira Jinguji's research profile covering reconfigurable computing, machine learning accelerators, and high-performance computing at RIKEN.">
    <title>神宮司明良 (AKIRA JINGUJI)</title>
    <link rel="icon" href="../assets/logo.png">
    <link rel="stylesheet" href="../assets/css/css.css">
    <script src="../assets/js/js.js" defer></script>
  </head>
  <body>
    <a class="skip-link" href="#main">Skip to content</a>
    <header class="site-header">
      <div class="header-inner">
        <a class="brand" href="index.html">
          <img src="../assets/kaojyashin.jpg" alt="Portrait of Akira Jinguji">
          <span>AKIRA JINGUJI</span>
        </a>
        <nav class="site-nav" id="primary-navigation" aria-label="Global navigation">
          <a href="index.html" aria-current="page">Home</a>
          <a href="publications.html">Publications</a>
          <div class="lang-toggle" role="group" aria-label="Language toggle">
            <a class="lang-option" href="../jp/index.html" lang="ja">JP</a>
            <span class="lang-separator">/</span>
            <span class="lang-option is-active" aria-current="true">EN</span>
          </div>
        </nav>
      </div>
    </header>

    <main id="main">
      <section class="hero">
        <div>
          <h1>Akira Jinguji</h1>
          <p class="meta">
            <span>- Research Scientist, RIKEN Center for CS</span>
            <span>- CEO, SpiceEngine Inc.</span>
          </p>
          <p>
            I explore hardware-aware acceleration for computation-intensive workloads, spanning FPGA-based machine learning, sparse neural network architectures, and high-performance computing.
            Recent papers investigate how supercomputers and large-scale GPU clusters shorten complex numerical workloads, while reconfigurable processors orchestrate inference and training pipelines.
            A major thrust is leveraging sparsity-aware dataflows and memory-light data paths on FPGA and CGRA platforms to accelerate neural operators with high fidelity.
            By tailoring the software stack and hardware implementations together, I aim to transition these AI acceleration capabilities into resilient, production-ready systems.
          </p>
        </div>
        <img src="../assets/baikunoshashin.jpg" alt="Laboratory equipment used in Akira Jinguji's research">
      </section>

      <section class="section">
        <div class="highlight">
          <h2>Highlights</h2>
          <p>Leading the Sparsity-aware Coarse-grained Reconfigurable Accelerator project with support from the Google Silicon Research Grant (FY2024–2025).</p>
        </div>
      </section>

      <section class="section">
        <h2>Research Themes</h2>
        <div class="grid-cards">
          <article class="card">
            <h3>High-Performance Computing</h3>
            <p>Designing scalable acceleration strategies for compute-intensive workloads on supercomputers and GPU clusters.</p>
          </article>
          <article class="card">
            <h3>Reconfigurable Computing</h3>
            <p>Designing FPGA-oriented architectures that balance agility and throughput for data-intensive applications.</p>
          </article>
          <article class="card">
            <h3>Machine Learning Accelerators</h3>
            <p>Building sparse neural network accelerators and near-memory computing fabrics for deep learning workloads.</p>
          </article>
        </div>
      </section>

      <section class="section">
        <h2>Recent Updates</h2>
        <ul class="pub-entries">
          <li>
            <strong>Journal Publication</strong>
            <span>Expanded research on scalable acceleration methods for large-scale numerical workloads.</span>
          </li>
          <li>
            <strong>Conference</strong>
            <span>Presented a vision transformer accelerator for near-memory computation at ARC 2023.</span>
          </li>
          <li>
            <strong>Award</strong>
            <span>Recipient of the IEICE Reconfigurable Systems Technical Committee Young Researchers Award (January 2022).</span>
          </li>
        </ul>
      </section>

      <section class="section">
        <h2>Selected Contributions</h2>
        <div class="grid-cards">
          <article class="card">
            <h3>Peer-reviewed Journals</h3>
            <p>Publications spanning FPGA training accelerators, sparse CNN deployment, and high-performance computing.</p>
          </article>
          <article class="card">
            <h3>International Conferences</h3>
            <p>Regular contributions to FPT, FPGA, FCCM, and related venues on reconfigurable and AI accelerators.</p>
          </article>
          <article class="card">
            <h3>Funding</h3>
            <p>Active projects backed by Google, JSPS, and industrial partners on sparse computing architectures.</p>
          </article>
        </div>
      </section>

      <section class="section">
        <div class="highlight">
          <h2>Explore Publications</h2>
          <p>For complete publication, award, and grant records, please visit the <a href="publications.html">English publications</a> page.</p>
        </div>
      </section>
    </main>
    <footer>
      &copy; 2025 Akira Jinguji
    </footer>
  </body>
</html>
